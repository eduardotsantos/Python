{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Multilayer Perceptron (MLP)**: é um perceptron multicamada é uma classe de rede neural artificial tipo feedforward, consistindo de pelo menos três camadas de nós, sendo uma camada de entrada, uma camada oculta e uma camada de saída. Exceto pelos nós de entrada, cada nó é um neurônio que usa uma função de ativação não linear. O MLP utiliza uma técnica de aprendizado supervisionado chamada retropropagação para treinamento, podendo distinguir dados que não são linearmente separáveis.\n",
        "\n",
        "Collobert, R.; Bengio, S. Links between perceptrons, MLPs and SVMs. ICML '04: Proceedings of the twenty-first international conference on Machine learning. https://doi.org/10.1145/1015330.1015415, 2004.\n",
        "\n",
        "Explicação do algoritmo MLP: https://youtu.be/oivb9285i54\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Support Vector Machine (SVM)**: método desenvolvido nos laboratórios da AT&T por Vapnik e Cortes em 1995 é um método de previsão baseado em aprendizagem estatística, que consiste em um conjunto de exemplos de treinamento, onde cada dados é rotulado como pertencente a uma das classes, classificando os dados, mapeando os pontos no espaço, objetivando maximizar a largura da lacuna entre as classes.\n",
        "\n",
        "Cortes, C.; Vapnik, V. Support-vector networks. Machine Learning. 20 (3): 273–297, Springer. https://doi.org/10.1007/BF00994018, 1995.\n",
        "\n",
        "Explicação do algoritmo SVM: https://youtu.be/UrR5tcY-wYw\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**K-Nearest Neighbors (KNN)**: método K vizinhos mais próximos foi proposto por Fukunaga e Narendra em 1975, se tornando um dos algoritmos para solução de problemas da classe de classificação mais usados, pois possui uma abordagem simples de ser implementada, apesar que para grandes volumes de dados irá usar muito recursos de hardware devido a base de sua lógica que consiste no cálculo de distância, e essa é uma tarefa custosa para o hardware, consumindo muito tempo computacional, e é um método que depende no fator K, assim quanto maior, mais recurso de hardware será consumido.\n",
        "\n",
        "Fukunaga, K.; Narendra, P. A Branch and Bound Algorithm for Computing k-Nearest Neighbors. IEEE Transactions on Computers Volume: C-24, Issue: 7. https://doi.org/10.1109/T-C.1975.224297, 1975.\n",
        "\n",
        "Explicação do algoritmo KNN: https://youtu.be/oafK8OGu_Vk"
      ],
      "metadata": {
        "id": "atNC9YQrN33T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P6tBY50QOHR"
      },
      "source": [
        "#instalar biblioteca Orange Canvas\n",
        "!pip install Orange3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importar biblioteca Orange Canvas\n",
        "import Orange"
      ],
      "metadata": {
        "id": "1MF20XTJ_Aa_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importar dados do disco local\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "Ygu12JE_Afct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instanciar objeto de dados com base no caminho gerado com a importação do arquivo\n",
        "dados = Orange.data.Table(\"/content/rotas.csv\")"
      ],
      "metadata": {
        "id": "Uid5eSz5Fiwi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imprimir os primeiros 5 registros\n",
        "for d in dados[:5]:\n",
        "  print(d)"
      ],
      "metadata": {
        "id": "ar06vvffknDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#explorar os metadados\n",
        "qtde_campos = len(dados.domain.attributes)\n",
        "qtde_cont = sum(1 for a in dados.domain.attributes if a.is_continuous)\n",
        "qtde_disc = sum(1 for a in dados.domain.attributes if a.is_discrete)\n",
        "print(\"%d metadados: %d continuos, %d discretos\" % (qtde_campos, qtde_cont, qtde_disc))\n",
        "print(\"Nome dos metadados:\", \", \".join(dados.domain.attributes[i].name for i in range(qtde_campos)),)"
      ],
      "metadata": {
        "id": "H5nbZkd6rDHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#explorar classe\n",
        "dados.domain.class_var"
      ],
      "metadata": {
        "id": "I3P5bR1Bts-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#criar amostra\n",
        "qtde100 = len(dados)\n",
        "qtde70 = len(dados) * 70 / 100\n",
        "qtde30 = len(dados) * 30 / 100\n",
        "print(\"Qtde 100%:\", qtde100)\n",
        "print(\"Qtde  70%:\", qtde70)\n",
        "print(\"Qtde  30%:\", qtde30)\n",
        "amostra = Orange.data.Table(dados.domain, [d for d in dados if d.row_index < qtde70])\n",
        "print(\"Registros:\", len(dados))\n",
        "print(\"Registros:\", len(amostra))"
      ],
      "metadata": {
        "id": "Ds75Qk7vusPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hiperparâmetros do Multilayer Perceptron\n",
        "\n",
        "hidden_layer_sizes=(100,): qtde de neurônios por camada(s) oculta(s).\n",
        "\n",
        "activation='relu': função de ativação para as camadas ocultas.\n",
        "\n",
        "solver='adam': solucionador para otimização de peso.\n",
        "\n",
        "alpha=0.0001: parâmetro de penalidade sendo L2 o prazo de regularização.\n",
        "\n",
        "batch_size='auto': Tamanho dos lotes para otimizadores estocásticos.\n",
        "\n",
        "learning_rate='constant': cronograma da taxa de aprendizado p/ atualizações de peso.\n",
        "\n",
        "learning_rate_init=0.001: taxa de aprendizado inicial.\n",
        "\n",
        "power_t=0.5: expoente para a taxa de aprendizado de escala inversa.\n",
        "\n",
        "shuffle=True: se as amostras devem ser embaralhadas em cada iteração.\n",
        "\n",
        "random_state=None: determina a geração de números aleatórios para inicialização de pesos e viés.\n",
        "\n",
        "tol=0.0001: Tolerância para a otimização.\n",
        "\n",
        "verbose=False: Se as mensagens de progresso devem ser impressas em stdout.\n",
        "\n",
        "warm_start=False: ativa/desativa a reutilização da solução da chamada anterior para caber como inicialização.\n",
        "\n",
        "momentum=0.9: atualização de gradiente descendente.\n",
        "\n",
        "nesterovs_momentum=True: ativa/desativa o impulso de Nesterov.\n",
        "\n",
        "early_stopping=False: ativa/desativa a interrupção antecipada para encerrar o treinamento quando a pontuação de validação não estiver melhorando.\n",
        "\n",
        "validation_fraction=0.1: proporção de dados de treinamento a serem reservados como validação definida para interrupção antecipada.\n",
        "\n",
        "beta_1=0.9: taxa de decaimento exponencial para estimativas do vetor de primeiro momento.\n",
        "\n",
        "beta_2=0.999: taxa de decaimento exponencial para estimativas do vetor de segundo momento.\n",
        "\n",
        "epsilon=1e-08: valor para estabilidade numérica.\n",
        "\n",
        "max_iter: número máximo de iterações.\n",
        "\n",
        "preprocessors: é usado o pré-processamento padrão quando nenhum outro pré-processador é fornecido. Ele os executa na seguinte ordem: remove instâncias com valores de destino desconhecidos; continua variáveis categóricas (com codificação one-hot); remove colunas vazias; imputa valores ausentes com valores médios."
      ],
      "metadata": {
        "id": "42ngrE0fMciM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Técnica Multi-Layer Perceptron (MLP)\n",
        "mlp = Orange.classification.NNClassificationLearner(\n",
        "    hidden_layer_sizes=(64,64),\n",
        "    activation='relu',\n",
        "    solver='sgd',\n",
        "    alpha=0.0001,\n",
        "    batch_size='auto',\n",
        "    learning_rate='constant',\n",
        "    learning_rate_init=0.001,\n",
        "    power_t=0.5, max_iter=200,\n",
        "    shuffle=True, random_state=None,\n",
        "    tol=0.0001, verbose=False,\n",
        "    warm_start=False,\n",
        "    momentum=0.9,\n",
        "    nesterovs_momentum=True,\n",
        "    early_stopping=False,\n",
        "    validation_fraction=0.1,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-08,\n",
        "    preprocessors=None)"
      ],
      "metadata": {
        "id": "RbAJ44FgLM00"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hiperparâmetros do Support Vector Machine\n",
        "\n",
        "C: quanto menor, mais larga será a margem, porém com mais chances de violação de margem (função custo).\n",
        "\n",
        "Kernel: determina a técnica para permitir o uso do SVM não linear com o default sendo o Radial Basis Function (RBF), mas também podendo ser utiliado o Linear, Polymonial e Sigmoid.\n",
        "\n",
        "Degree: determina o grau que o kernel irá utilizar e o default é 3.\n",
        "\n",
        "Gamma: determina o valor recomendado para o Kernel de 1/k, onde k é o número de atributos.\n",
        "\n",
        "Coef0: controla o quanto o modelo é influenciado por polinômios de alto grau versus polinômios de baixo grau.\n",
        "\n",
        "Shrinking: ativa/desativa o método heurístico de escolha.\n",
        "\n",
        "Probability: ativa/desativa a construção de um modelo propabilítico.\n",
        "\n",
        "Tol: taxa de tolerância do critério de rescisão.\n",
        "\n",
        "Cache_size: tamanho da memória cache em MB\n",
        "\n",
        "Max_iter: número máximo de iterações.\n",
        "\n",
        "Preprocessors: é usado o pré-processamento padrão quando nenhum outro pré-processador é fornecido. Ele os executa na seguinte ordem: remove instâncias com valores de destino desconhecidos; continua variáveis categóricas (com codificação one-hot); remove colunas vazias; imputa valores ausentes com valores médios."
      ],
      "metadata": {
        "id": "v7VBWYllAhMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Técnica Support Vector Machine (SVM)\n",
        "svm = Orange.classification.SVMLearner(\n",
        "    C=1.0,\n",
        "    kernel='rbf',\n",
        "    degree=5,\n",
        "    gamma='auto',\n",
        "    coef0=0.0,\n",
        "    shrinking=True,\n",
        "    probability=False,\n",
        "    tol=0.001,\n",
        "    cache_size=200,\n",
        "    max_iter=200,\n",
        "    preprocessors=None)"
      ],
      "metadata": {
        "id": "8JS4MeIPAzuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hiperparâmetros do K-Nearest Neighbors\n",
        "\n",
        "n_neighbors: valor correspondente a quantidade de vizinhos mais próximos.\n",
        "\n",
        "metric: métrica a ser utilizada para cálculo da distância com o default sendo a euclidiana.\n",
        "\n",
        "weights: determina se o peso será distance onde os vizinhos mais próximos têm influência maior, ou se uniform onde todos os pontos em cada vizinhança são ponderados igualmente.\n",
        "\n",
        "preprocessors: é usado o pré-processamento padrão quando nenhum outro pré-processador é fornecido. Ele os executa na seguinte ordem: remove instâncias com valores de destino desconhecidos; continua variáveis categóricas (com codificação one-hot); remove colunas vazias; imputa valores ausentes com valores médios."
      ],
      "metadata": {
        "id": "_ttExRKaArN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Técnica K-Nearest Neightbors (KNN)\n",
        "knn = Orange.classification.KNNLearner(\n",
        "    n_neighbors=5,\n",
        "    metric='euclidean',\n",
        "    weights='distance',\n",
        "    algorithm='auto',\n",
        "    metric_params=None,\n",
        "    preprocessors=None)"
      ],
      "metadata": {
        "id": "y1zzsZZfAzSt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validar o aprendizado para as 3 técnicas\n",
        "aprendizado = [mlp, svm, knn]\n",
        "avaliacao = Orange.evaluation.CrossValidation(dados, aprendizado, k=5)"
      ],
      "metadata": {
        "id": "_vNTaCAHS5bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imprimir os indicadores para as 3 técnicas\n",
        "print(\" \" * 10 + \" | \".join(\"%-4s\" % learner.name for learner in aprendizado))\n",
        "print(\"MSE..................  %s\" % \" | \".join(\"%.2f\" % s for s in Orange.evaluation.MSE(avaliacao))) #Erro Médio Quadrático\n",
        "print(\"RMSE.................  %s\" % \" | \".join(\"%.2f\" % s for s in Orange.evaluation.RMSE(avaliacao))) #Raiz do Erro Médio Quadrático\n",
        "print(\"MAE..................  %s\" % \" | \".join(\"%.2f\" % s for s in Orange.evaluation.MAE(avaliacao))) #Erro Médio Absoluto\n",
        "print(\"R2...................  %s\" % \" | \".join(\"%.2f\" % s for s in Orange.evaluation.R2(avaliacao))) #Coeficiênte da Determinação\n",
        "print(\"RMSE.................  %s\" % \" | \".join(\"%.2f\" % s for s in Orange.evaluation.RMSE(avaliacao))) #Coeficiênte da Variação do RMSE\n",
        "#print(\"Acurácia  %s\" % \" | \".join(\"%.2f\" % s for s in Orange.evaluation.CA(avaliacao))) #A =  (VP+VN) / (VP+VN+FP+FN)\n",
        "#print(\"Precisão  %s\" % \" | \".join(\"%.2f\" % s for s in Orange.evaluation.Precision(avaliacao))) #P = (VP) / (VP + FP)\n",
        "#print(\"Revocação %s\" % \" | \".join(\"%.2f\" % s for s in Orange.evaluation.Recall(avaliacao))) #R = (VP) / (VP + FN)\n",
        "#print(\"F1        %s\" % \" | \".join(\"%.2f\" % s for s in Orange.evaluation.F1(avaliacao))) #F = 2 * ((Precisão * Revocação) / (Precisão + Revocação))\n",
        "#print(\"ROC       %s\" % \" | \".join(\"%.2f\" % s for s in Orange.evaluation.AUC(avaliacao))) #"
      ],
      "metadata": {
        "id": "dtxG4yrDTAtv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "859a8765-52b2-47ec-9c87-117b52176f82"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          nn classification | svm  | knn \n",
            "MSE..................  4.72 | 4.72 | 4.72\n",
            "RMSE.................  2.17 | 2.17 | 2.17\n",
            "MAE..................  2.01 | 2.01 | 2.01\n",
            "R2...................  -6.02 | -6.02 | -6.02\n",
            "RMSE.................  2.17 | 2.17 | 2.17\n"
          ]
        }
      ]
    }
  ]
}